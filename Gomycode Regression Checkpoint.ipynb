{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5620e601",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "- Import you data and perform basic data exploration phase\n",
    "   - Display general information about the dataset\n",
    "   - Create a pandas profiling reports to gain insights into the dataset\n",
    "   - Handle Missing and corrupted values\n",
    "   - Remove duplicates, if they exist\n",
    "   - Handle outliers, if they exist\n",
    "- Encode categorical features\n",
    "- Select your target variable and the features\n",
    "- Split your dataset to training and test sets\n",
    "- Based on your data exploration phase select a ML regression algorithm and train it on the training set\n",
    "- Assess your model performance on the test set using relevant evaluation metrics\n",
    "- Discuss with your cohort alternative ways to improve your modelÂ performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7c0d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d03c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc14f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_df = pd.read_csv(\"5G_energy_consumption_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c386069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df892bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1a1b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_df['Time'] = pd.to_datetime(energy_df['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4116c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d1cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_df['Time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ea3569",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_df['BS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3460363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51455105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b30a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(energy_df, title = \"Energy Consumption Report\", explorative = True)\n",
    "profile.to_file(\"energy_profile_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8b2bf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de8efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_df = energy_df.drop(\"ESMODE\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734e5940",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_df = energy_df.drop(\"Time\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2145c8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f10e051",
   "metadata": {},
   "outputs": [],
   "source": [
    "le =LabelEncoder()\n",
    "\n",
    "energy_df[\"BS\"] = le.fit_transform(energy_df[\"BS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df57e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "numerical_features = energy_df.select_dtypes(include='number').columns\n",
    "plt.figure(figsize=(25, 25))\n",
    "for i in range(0, len(numerical_features)):\n",
    "    plt.subplot(10, 4, i+1)\n",
    "    sns.boxplot(x = energy_df[numerical_features[i]], palette = 'viridis')\n",
    "    plt.title(numerical_features[i], fontsize = 30)\n",
    "    plt.xlabel(' ')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9d404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data manipulation and visualization\n",
    "import numpy as np  # For numerical operations\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "from scipy import stats  # Import stats module for Z-score\n",
    "import matplotlib.pyplot as plt  # For plotting data\n",
    "import seaborn as sns  # For enhanced data visualizations\n",
    "from scipy import stats # For statistics\n",
    "\n",
    "# Import libraries for machine learning models and evaluation\n",
    "from sklearn.model_selection import train_test_split  # For splitting data into training and testing sets\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder  # For scaling numerical data and encoding categorical data\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet  # For linear Regression\n",
    "from sklearn.tree import DecisionTreeRegressor  # For Decision Tree Regression\n",
    "from sklearn.ensemble import RandomForestRegressor  # For Random Forest Regression\n",
    "from sklearn.svm import SVR  # For Support Vector Regression \n",
    "import xgboost as xgb # For XGBoost Regression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer  # For model evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0471fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = energy_df.drop(columns=['Energy'])  # Drop the target column to get features\n",
    "y = energy_df['Energy']  # Select the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e741200",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6391de66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acaba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "lin_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicting on test data\n",
    "y_pred_lr = lin_reg.predict(X_test_scaled)\n",
    "\n",
    "# Model evaluation\n",
    "print(\"Linear Regression RMSE:\", mean_squared_error(y_test, y_pred_lr, squared=False))\n",
    "print(\"Linear Regression R2 Score:\", r2_score(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f477126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Initialize the Elastic Net model\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "elastic_net.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicting on test data\n",
    "y_pred_en = elastic_net.predict(X_test_scaled)\n",
    "\n",
    "# Model evaluation\n",
    "print(\"Elastic Net RMSE:\", mean_squared_error(y_test, y_pred_en, squared=False))\n",
    "print(\"Elastic Net R2 Score:\", r2_score(y_test, y_pred_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0230ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with some parameters\n",
    "tree_reg = DecisionTreeRegressor(max_depth=5, min_samples_split=10, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "tree_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicting on test data\n",
    "y_pred_tree = tree_reg.predict(X_test_scaled)\n",
    "\n",
    "# Model evaluation\n",
    "print(\"Decision Tree RMSE:\", mean_squared_error(y_test, y_pred_tree, squared=False))\n",
    "print(\"Decision Tree R2 Score:\", r2_score(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48ed1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with some parameters\n",
    "rf_reg = RandomForestRegressor(n_estimators=100, max_depth=10, min_samples_split=5, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicting on test data\n",
    "y_pred_rf = rf_reg.predict(X_test_scaled)\n",
    "\n",
    "# Model evaluation\n",
    "print(\"Random Forest RMSE:\", mean_squared_error(y_test, y_pred_rf, squared=False))\n",
    "print(\"Random Forest R2 Score:\", r2_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e63613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with some parameters\n",
    "svr_reg = SVR(kernel='rbf', C=100, epsilon=0.1)\n",
    "\n",
    "# Fit the model\n",
    "svr_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicting on test data\n",
    "y_pred_svr = svr_reg.predict(X_test_scaled)\n",
    "\n",
    "# Model evaluation\n",
    "print(\"SVR RMSE:\", mean_squared_error(y_test, y_pred_svr, squared=False))\n",
    "print(\"SVR R2 Score:\", r2_score(y_test, y_pred_svr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14de33bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with some parameters\n",
    "xgb_reg = xgb.XGBRegressor(n_estimators=100, learning_rate=0.05, max_depth=6)\n",
    "\n",
    "# Fit the model\n",
    "xgb_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicting on test data\n",
    "y_pred_xgb = xgb_reg.predict(X_test_scaled)\n",
    "\n",
    "# Model evaluation\n",
    "print(\"XGBoost RMSE:\", mean_squared_error(y_test, y_pred_xgb, squared=False))\n",
    "print(\"XGBoost R2 Score:\", r2_score(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98736cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary functions from scikit-learn\n",
    "from sklearn.metrics import make_scorer  # To create custom scoring functions\n",
    "from sklearn.model_selection import cross_validate  # To perform cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68853d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the XGBoost model\n",
    "model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.05, max_depth=6, random_state=42)\n",
    "\n",
    "# Create custom scorers for RMSE and RÂ²\n",
    "# `make_scorer` allows using custom metrics or built-in metrics in cross-validation\n",
    "rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
    "r2_scorer = make_scorer(r2_score)\n",
    "\n",
    "# Dictionary of scoring metrics\n",
    "scoring = {'RMSE': rmse_scorer, 'R2': r2_scorer}\n",
    "\n",
    "# Perform cross-validation\n",
    "# `cross_validate` splits the data into folds, trains and tests the model, and calculates the scores\n",
    "cv_results = cross_validate(model, X, y, scoring=scoring, cv=5, return_train_score=True)\n",
    "# Note that we are using X and y and not X_train and y_train\n",
    "\n",
    "# Output the results\n",
    "# `cv_results` contains the scores for each fold\n",
    "print(\"RMSE scores:\", cv_results['test_RMSE'])  # RMSE scores for each fold\n",
    "print(\"RÂ² scores:\", cv_results['test_R2'])  # RÂ² scores for each fold\n",
    "print(\"Average RMSE:\", cv_results['test_RMSE'].mean())  # Average RMSE across all folds\n",
    "print(\"Average RÂ²:\", cv_results['test_R2'].mean())  # Average RÂ² score across all folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357d187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use XGBoost and tune the n_estimators, learning_rate, and max_depth.\n",
    "\n",
    "# Initialize the best RMSE and best RÂ² to extreme values to ensure any calculated values will be better\n",
    "best_rmse = float('inf')\n",
    "best_r2 = -float('inf')\n",
    "best_params = {}\n",
    "\n",
    "# Iterate over different values for n_estimators, learning_rate, and max_depth\n",
    "for n_estimators in [50, 100, 200]:  # Number of boosting rounds\n",
    "    for learning_rate in [0.01, 0.1, 0.2]:  # Step size at each iteration\n",
    "        for max_depth in range(3, 10, 2):  # Maximum depth of each tree\n",
    "\n",
    "            # Initialize the XGBoost model with the current set of hyperparameters\n",
    "            xgb_reg = xgb.XGBRegressor(\n",
    "                n_estimators=n_estimators,       # Number of boosting rounds\n",
    "                learning_rate=learning_rate,     # Step size at each iteration\n",
    "                max_depth=max_depth,             # Maximum depth of each tree\n",
    "                random_state=42                  # Ensures reproducibility\n",
    "            )\n",
    "            \n",
    "            # Train the model using the training data\n",
    "            xgb_reg.fit(X_train, y_train)\n",
    "            \n",
    "            # Predict the target values for the test data\n",
    "            y_pred_xgb = xgb_reg.predict(X_test)\n",
    "            \n",
    "            # Calculate Root Mean Squared Error (RMSE) and RÂ² score for the current model\n",
    "            rmse = mean_squared_error(y_test, y_pred_xgb, squared=False)\n",
    "            r2 = r2_score(y_test, y_pred_xgb)\n",
    "            \n",
    "            # Check if the current RMSE is better (lower) than the best RMSE so far\n",
    "            if rmse < best_rmse:\n",
    "                # Update the best RMSE, RÂ² score, and the best parameters\n",
    "                best_rmse = rmse\n",
    "                best_r2 = r2\n",
    "                best_params = {\n",
    "                    'n_estimators': n_estimators, \n",
    "                    'learning_rate': learning_rate, \n",
    "                    'max_depth': max_depth\n",
    "                }\n",
    "\n",
    "# Print the best hyperparameters and corresponding RMSE and RÂ² score\n",
    "print(\"Best Parameters for XGBoost:\", best_params)\n",
    "print(\"Best RMSE for XGBoost:\", best_rmse)\n",
    "print(\"Best RÂ² Score for XGBoost:\", best_r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
